{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('./data/df_social_data_train.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982389e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processar e extrair caracteristicas dos dados para construir a tabela atributo-valor\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8312a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['features'] = list(model.encode(df['content'].tolist(), show_progress_bar=True))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['content','features']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "k = 15\n",
    "X = np.array(df.features.to_list()) # conjunto de dados\n",
    "\n",
    "kmeans = KMeans(n_clusters=9, random_state=0, n_init=\"auto\").fit(X)\n",
    "df['cluster'] = kmeans.labels_\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c075fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "df_sample = df.sample(5000)\n",
    "X_sample = np.array(df_sample.features.to_list())\n",
    "Y_sample = np.array(df_sample.cluster.to_list())\n",
    "\n",
    "features2D = umap.UMAP().fit_transform(X_sample, y=Y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0143656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='white', context='poster')\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(7, 5))\n",
    "plt.scatter(*features2D.T, s=0.1, c=df_sample.cluster.to_list(), cmap='Spectral', alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24697a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e455bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import openai\n",
    "\n",
    "def llm_local():\n",
    "  modo_local = input(\"Deseja usar uma LLM local? (s/n): \").strip().lower()\n",
    "\n",
    "  if modo_local == 's':\n",
    "      # Configuração para Ollama local\n",
    "      openai.api_base = \"http://localhost:11434/v1\"\n",
    "      openai.api_key = \"ollama\"  # Requerido por algumas bibliotecas mesmo que não usado\n",
    "  else:\n",
    "      # Configuração para OpenAI\n",
    "      openai.api_base = \"https://api.openai.com/v1\"\n",
    "      openai.api_key = getpass(\"Digite sua chave de API da OpenAI: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ffdb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "def llm_task(model, system, prompt):\n",
    "  response = openai.ChatCompletion.create(\n",
    "      model=model,\n",
    "      messages = [\n",
    "            {\n",
    "              \"role\": \"system\",\n",
    "              \"content\": system\n",
    "            },\n",
    "            {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": prompt\n",
    "            },\n",
    "          ]\n",
    "\n",
    "  )\n",
    "  s = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "!pip install ollama\n",
    "!nohup ollama serve &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9549d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baixando uma LLM (llama3.1)\n",
    "!ollama pull llama3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52dedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = '''\n",
    "Você é um analista de posts em redes sociais.\n",
    "A partir de uma lista de posts, você deve:\n",
    "1) identificar o tema geral dos posts\n",
    "2) identificar os tópicos mais relevantes nos posts.\n",
    "3) cada tópico deve ser formado 2 ou 3 palavras\n",
    "4) sumarizar posts positivos e negativos\n",
    "5) Apresentar um breve resumo dos posts\n",
    "A saída da análise deve ser estruturada em JSON.\n",
    "\n",
    "Exemplo de Estrutura do JSON:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"tema_geral\": \"texto do tema geral\",\n",
    "  \"topicos_relevantes\": [\"topico A\",\"topico B\",\"topico C\"],\n",
    "  \"resumo_positivo\": \"resumir posts positivos\",\n",
    "  \"resumo_negativo\": \"resumir posts negativos\"\n",
    "}\n",
    "```\n",
    "\n",
    "A resposta deve ser em português e APENAS EM JSON.\n",
    "Não retorne nada além do JSON.\n",
    "'''\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25422842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "L = []\n",
    "temp_dict = {}\n",
    "for cluster in range(0,9):\n",
    "  print(\"Gerando analise do cluster\",cluster)\n",
    "  prompt = ''\n",
    "  df_temp = df[df.cluster == cluster].sample(10)\n",
    "  for index,row in df_temp.iterrows():\n",
    "    prompt += f'#Post: {row.content} ####\\n\\n\\n'\n",
    "  resposta = llm_task(\"llama3.1\",system,prompt)\n",
    "  print(resposta)\n",
    "  json_str = resposta.replace(\"```json\",\"\").replace(\"```\",\"\")\n",
    "  print(json_str)\n",
    "  obj = json.loads(json_str)\n",
    "  print(obj)\n",
    "  df_temp['tema_geral'] = obj['tema_geral']\n",
    "  df_temp['topicos_relevantes'] = str(list(obj['topicos_relevantes']))\n",
    "  df_temp['resumo_positivo'] = str(list(obj['resumo_positivo']))\n",
    "  df_temp['resumo_negativo'] = str(list(obj['resumo_negativo']))\n",
    "  L.append(df_temp)\n",
    "  temp_dict[cluster] = obj\n",
    "  print(\"======\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = pd.concat(L)\n",
    "df_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd9641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters[['content','tema_geral','topicos_relevantes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f136fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in temp_dict.items():\n",
    "  print(\"Cluster: \", key)\n",
    "  print(\"Tema Geral: \", value['tema_geral'])\n",
    "  print(\"Tópicos Relevantes: \", value['topicos_relevantes'])\n",
    "  print(\"Resumo Positivo: \", value['resumo_positivo'])\n",
    "  print(\"Resumo Negativo: \", value['resumo_negativo'])\n",
    "  print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
